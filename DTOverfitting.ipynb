{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version of GraphLab Create (v1.8.5) is available! Your current version is v1.8.3.\n",
      "\n",
      "You can use pip to upgrade the graphlab-create package. For more information see https://dato.com/products/create/upgrade.\n"
     ]
    }
   ],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] GraphLab Create v1.8.3 started. Logging: C:\\Users\\ritraina\\AppData\\Local\\Temp\\graphlab_server_1460685561.log.0\n"
     ]
    }
   ],
   "source": [
    "loans = graphlab.SFrame('lending-club-data.gl/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans = loans.remove_column('bad_loans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home_ownership status: own, mortgage or rent\n",
    "            'emp_length',         # number of years of employment\n",
    "           ]\n",
    "target = 'safe_loans'\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of safe loans                 : 0.502236174422\n",
      "Percentage of risky loans                : 0.497763825578\n",
      "Total number of loans in our new dataset : 46508\n"
     ]
    }
   ],
   "source": [
    "safe_loans_raw = loans[loans[target] == 1]\n",
    "risky_loans_raw = loans[loans[target] == -1]\n",
    "\n",
    "# Since there are less risky loans than safe loans, find the ratio of the sizes\n",
    "# and use that percentage to undersample the safe loans.\n",
    "percentage = len(risky_loans_raw)/float(len(safe_loans_raw))\n",
    "safe_loans = safe_loans_raw.sample(percentage, seed = 1)\n",
    "risky_loans = risky_loans_raw\n",
    "loans_data = risky_loans.append(safe_loans)\n",
    "\n",
    "print \"Percentage of safe loans                 :\", len(safe_loans) / float(len(loans_data))\n",
    "print \"Percentage of risky loans                :\", len(risky_loans) / float(len(loans_data))\n",
    "print \"Total number of loans in our new dataset :\", len(loans_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loans_data = risky_loans.append(safe_loans)\n",
    "for feature in features:\n",
    "    loans_data_one_hot_encoded = loans_data[feature].apply(lambda x: {x: 1})    \n",
    "    loans_data_unpacked = loans_data_one_hot_encoded.unpack(column_name_prefix=feature)\n",
    "    \n",
    "    # Change None's to 0's\n",
    "    for column in loans_data_unpacked.column_names():\n",
    "        loans_data_unpacked[column] = loans_data_unpacked[column].fillna(0)\n",
    "\n",
    "    loans_data.remove_column(feature)\n",
    "    loans_data.add_columns(loans_data_unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grade.A',\n",
       " 'grade.B',\n",
       " 'grade.C',\n",
       " 'grade.D',\n",
       " 'grade.E',\n",
       " 'grade.F',\n",
       " 'grade.G',\n",
       " 'term. 36 months',\n",
       " 'term. 60 months',\n",
       " 'home_ownership.MORTGAGE',\n",
       " 'home_ownership.OTHER',\n",
       " 'home_ownership.OWN',\n",
       " 'home_ownership.RENT',\n",
       " 'emp_length.1 year',\n",
       " 'emp_length.10+ years',\n",
       " 'emp_length.2 years',\n",
       " 'emp_length.3 years',\n",
       " 'emp_length.4 years',\n",
       " 'emp_length.5 years',\n",
       " 'emp_length.6 years',\n",
       " 'emp_length.7 years',\n",
       " 'emp_length.8 years',\n",
       " 'emp_length.9 years',\n",
       " 'emp_length.< 1 year',\n",
       " 'emp_length.n/a']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = loans_data.column_names()\n",
    "features.remove('safe_loans')  # Remove the response variable\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, validation_set = loans_data.random_split(.8, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reached_minimum_node_size(data, min_node_size):\n",
    "    # Return True if the number of data points is less than or equal to the minimum node size.\n",
    "    ## YOUR CODE HERE\n",
    "    if len(data) <= min_node_size:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def error_reduction(error_before_split, error_after_split):\n",
    "    # Return the error before the split minus the error after the split.\n",
    "    ## YOUR CODE HERE\n",
    "    gain_in_error = (error_before_split - error_after_split)\n",
    "    return gain_in_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intermediate_node_num_mistakes(labels_in_node):\n",
    "    # Corner case: If labels_in_node is empty, return 0\n",
    "    if len(labels_in_node) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Count the number of 1's (safe loans)\n",
    "    safe_loans = 0\n",
    "    risky_loans= 0\n",
    "    for i in range(len(labels_in_node)):\n",
    "        if labels_in_node[i] == 1:\n",
    "            safe_loans = safe_loans + 1\n",
    "        else:\n",
    "            risky_loans = risky_loans + 1\n",
    "    \n",
    "    # Count the number of -1's (risky loans)\n",
    "    # Return the number of mistakes that the majority classifier makes.\n",
    "    ##\n",
    "    num_mistakes = 0\n",
    "    if safe_loans > risky_loans:\n",
    "        num_mistakes = risky_loans\n",
    "    else:\n",
    "        num_mistakes = safe_loans\n",
    "    return num_mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_splitting_feature(data, features, target):\n",
    "    \n",
    "    best_feature = None # Keep track of the best feature \n",
    "    best_error = 10     # Keep track of the best error so far \n",
    "    # Note: Since error is always <= 1, we should intialize it with something larger than 1.\n",
    "\n",
    "    # Convert to float to make sure error gets computed correctly.\n",
    "    num_data_points = float(len(data))  \n",
    "    \n",
    "    # Loop through each feature to consider splitting on that feature\n",
    "    for feature in features:\n",
    "        \n",
    "        # The left split will have all data points where the feature value is 0\n",
    "        left_split = data[data[feature] == 0]\n",
    "        \n",
    "        \n",
    "        # The right split will have all data points where the feature value is 1\n",
    "        ## YOUR CODE HERE\n",
    "        right_split =  data[data[feature] == 1]\n",
    "            \n",
    "        # Calculate the number of misclassified examples in the left split.\n",
    "        # Remember that we implemented a function for this! (It was called intermediate_node_num_mistakes)\n",
    "        # YOUR CODE HERE\n",
    "        left_mistakes =  intermediate_node_num_mistakes(left_split[target])             \n",
    "      \n",
    "        # Calculate the number of misclassified examples in the right split.\n",
    "        ## YOUR CODE HERE\n",
    "        right_mistakes = intermediate_node_num_mistakes(right_split[target])\n",
    "        \n",
    "        # Compute the classification error of this split.\n",
    "        # Error = (# of mistakes (left) + # of mistakes (right)) / (# of data points)\n",
    "        ## YOUR CODE HERE\n",
    "        error = (right_mistakes + left_mistakes)/float(num_data_points)\n",
    "      \n",
    "        # If this is the best error we have found so far, store the feature as best_feature and the error as best_error\n",
    "        ## YOUR CODE HERE\n",
    "        if error < best_error:\n",
    "            best_error = error\n",
    "            best_feature = feature\n",
    "        \n",
    "    \n",
    "    return best_feature # Return the best feature we found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_leaf(target_values):\n",
    "    \n",
    "    # Create a leaf node\n",
    "    leaf = {'splitting_feature' : None,\n",
    "            'left' : None,\n",
    "            'right' : None,\n",
    "            'is_leaf': True,\n",
    "            'prediction': None}   ## YOUR CODE HERE\n",
    "    \n",
    "    # Count the number of data points that are +1 and -1 in this node.\n",
    "    num_ones = len(target_values[target_values == +1])\n",
    "    num_minus_ones = len(target_values[target_values == -1])\n",
    "    \n",
    "    # For the leaf node, set the prediction to be the majority class.\n",
    "    # Store the predicted class (1 or -1) in leaf['prediction']\n",
    "    if num_ones > num_minus_ones:\n",
    "        leaf['prediction'] = 1        ## YOUR CODE HERE\n",
    "    else:\n",
    "        leaf['prediction'] = -1       ## YOUR CODE HERE\n",
    "        \n",
    "    # Return the leaf node        \n",
    "    return leaf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def decision_tree_create(data, features, target, current_depth = 0, \n",
    "                         max_depth = 10, min_node_size=1, \n",
    "                         min_error_reduction=0.0):\n",
    "    \n",
    "    remaining_features = features[:] # Make a copy of the features.\n",
    "    \n",
    "    target_values = data[target]\n",
    "    print \"--------------------------------------------------------------------\"\n",
    "    print \"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values))\n",
    "    \n",
    "    \n",
    "    # Stopping condition 1: All nodes are of the same type.\n",
    "    if intermediate_node_num_mistakes(target_values) == 0:\n",
    "        print \"Stopping condition 1 reached. All data points have the same target value.\"                \n",
    "        return create_leaf(target_values)\n",
    "    \n",
    "    # Stopping condition 2: No more features to split on.\n",
    "    if remaining_features == []:\n",
    "        print \"Stopping condition 2 reached. No remaining features.\"                \n",
    "        return create_leaf(target_values)    \n",
    "    \n",
    "    # Early stopping condition 1: Reached max depth limit.\n",
    "    if current_depth >= max_depth:\n",
    "        print \"Early stopping condition 1 reached. Reached maximum depth.\"\n",
    "        return create_leaf(target_values)\n",
    "    \n",
    "    # Early stopping condition 2: Reached the minimum node size.\n",
    "    # If the number of data points is less than or equal to the minimum size, return a leaf.\n",
    "    if  reached_minimum_node_size(data, min_node_size) == 'True':         ## YOUR CODE HERE \n",
    "        print \"Early stopping condition 2 reached. Reached minimum node size.\"\n",
    "        return create_leaf(target_values)\n",
    "    \n",
    "    # Find the best splitting feature\n",
    "    splitting_feature = best_splitting_feature(data, features, target)\n",
    "    \n",
    "    # Split on the best feature that we found. \n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1]\n",
    "    \n",
    "    # Early stopping condition 3: Minimum error reduction\n",
    "    # Calculate the error before splitting (number of misclassified examples \n",
    "    # divided by the total number of examples)\n",
    "    error_before_split = intermediate_node_num_mistakes(target_values) / float(len(data))\n",
    "    \n",
    "    # Calculate the error after splitting (number of misclassified examples \n",
    "    # in both groups divided by the total number of examples)\n",
    "    left_mistakes = intermediate_node_num_mistakes(left_split[target]) ## YOUR CODE HERE\n",
    "    right_mistakes = intermediate_node_num_mistakes(right_split[target])  ## YOUR CODE HERE\n",
    "    error_after_split = (left_mistakes + right_mistakes) / float(len(data))\n",
    "    \n",
    "    # If the error reduction is LESS THAN OR EQUAL TO min_error_reduction, return a leaf.\n",
    "    if  error_reduction(error_before_split, error_after_split) <= min_error_reduction:      ## YOUR CODE HERE\n",
    "        print \"Early stopping condition 3 reached. Minimum error reduction.\"\n",
    "        return create_leaf(target_values)  ## YOUR CODE HERE \n",
    "    \n",
    "    \n",
    "    remaining_features.remove(splitting_feature)\n",
    "    print \"Split on feature %s. (%s, %s)\" % (\\\n",
    "                      splitting_feature, len(left_split), len(right_split))\n",
    "    \n",
    "    \n",
    "    # Repeat (recurse) on left and right subtrees\n",
    "    left_tree = decision_tree_create(left_split, remaining_features, target, \n",
    "                                     current_depth + 1, max_depth, min_node_size, min_error_reduction)        \n",
    "    \n",
    "    ## YOUR CODE HERE\n",
    "    right_tree = decision_tree_create(right_split, remaining_features, target, \n",
    "                                     current_depth + 1, max_depth, min_node_size, min_error_reduction)\n",
    "    \n",
    "    \n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "Split on feature grade.D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "small_decision_tree = decision_tree_create(train_data, features, 'safe_loans', max_depth = 2, \n",
    "                                        min_node_size = 10, min_error_reduction=0.0)\n",
    "if count_nodes(small_decision_tree) == 7:\n",
    "    print 'Test passed!'\n",
    "else:\n",
    "    print 'Test failed... try again!'\n",
    "    print 'Number of nodes found                :', count_nodes(small_decision_tree)\n",
    "    print 'Number of nodes that should be there : 5' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Split on feature emp_length.n/a. (96, 5)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (96 data points).\n",
      "Split on feature emp_length.< 1 year. (85, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (85 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (11 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "Split on feature grade.D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "Split on feature grade.E. (22024, 1276)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (22024 data points).\n",
      "Split on feature grade.F. (21666, 358)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (21666 data points).\n",
      "Split on feature emp_length.n/a. (20734, 932)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (20734 data points).\n",
      "Split on feature grade.G. (20638, 96)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (20638 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (96 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (932 data points).\n",
      "Split on feature grade.A. (702, 230)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (702 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (230 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (358 data points).\n",
      "Split on feature emp_length.8 years. (347, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (347 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Split on feature home_ownership.OWN. (9, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (9 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1276 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n"
     ]
    }
   ],
   "source": [
    "my_decision_tree_new = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                                min_node_size = 100, min_error_reduction=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "Split on feature grade.B. (8074, 1048)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (8074 data points).\n",
      "Split on feature grade.C. (5884, 2190)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (5884 data points).\n",
      "Split on feature grade.D. (3826, 2058)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (3826 data points).\n",
      "Split on feature grade.E. (1693, 2133)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1693 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2133 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2058 data points).\n",
      "Split on feature grade.E. (2058, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2058 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (2190 data points).\n",
      "Split on feature grade.D. (2190, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2190 data points).\n",
      "Split on feature grade.E. (2190, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2190 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1048 data points).\n",
      "Split on feature emp_length.5 years. (969, 79)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (969 data points).\n",
      "Split on feature grade.C. (969, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (969 data points).\n",
      "Split on feature grade.D. (969, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (969 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (79 data points).\n",
      "Split on feature home_ownership.MORTGAGE. (34, 45)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (34 data points).\n",
      "Split on feature grade.C. (34, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (34 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (45 data points).\n",
      "Split on feature grade.C. (45, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (45 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Split on feature emp_length.n/a. (96, 5)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (96 data points).\n",
      "Split on feature emp_length.< 1 year. (85, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (85 data points).\n",
      "Split on feature grade.B. (85, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (85 data points).\n",
      "Split on feature grade.C. (85, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (85 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (11 data points).\n",
      "Split on feature grade.B. (11, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Split on feature grade.C. (11, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (11 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5 data points).\n",
      "Split on feature grade.B. (5, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (5 data points).\n",
      "Split on feature grade.C. (5, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (5 data points).\n",
      "Split on feature grade.D. (5, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (5 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "Split on feature grade.D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "Split on feature grade.E. (22024, 1276)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (22024 data points).\n",
      "Split on feature grade.F. (21666, 358)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (21666 data points).\n",
      "Split on feature emp_length.n/a. (20734, 932)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (20734 data points).\n",
      "Split on feature grade.G. (20638, 96)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (20638 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (96 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (932 data points).\n",
      "Split on feature grade.A. (702, 230)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (702 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (230 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (358 data points).\n",
      "Split on feature emp_length.8 years. (347, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (347 data points).\n",
      "Split on feature grade.A. (347, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (347 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Split on feature home_ownership.OWN. (9, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (9 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1276 data points).\n",
      "Split on feature grade.A. (1276, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1276 data points).\n",
      "Split on feature grade.B. (1276, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1276 data points).\n",
      "Split on feature grade.C. (1276, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1276 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "Split on feature grade.A. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (4701 data points).\n",
      "Split on feature grade.B. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4701 data points).\n",
      "Split on feature grade.C. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (4701 data points).\n",
      "Split on feature grade.E. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (4701 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n"
     ]
    }
   ],
   "source": [
    "my_decision_tree_old = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                                min_node_size = 0, min_error_reduction=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(tree, x, annotate = False):   \n",
    "    # if the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        if annotate: \n",
    "            print \"At leaf, predicting %s\" % tree['prediction']\n",
    "        return tree['prediction'] \n",
    "    else:\n",
    "        # split on feature.\n",
    "        split_feature_value = x[tree['splitting_feature']]\n",
    "        if annotate: \n",
    "            print \"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value)\n",
    "        if split_feature_value == 0:\n",
    "            return classify(tree['left'], x, annotate)\n",
    "        else:\n",
    "            return classify(tree['right'], x, annotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emp_length.1 year': 0L,\n",
       " 'emp_length.10+ years': 0L,\n",
       " 'emp_length.2 years': 1L,\n",
       " 'emp_length.3 years': 0L,\n",
       " 'emp_length.4 years': 0L,\n",
       " 'emp_length.5 years': 0L,\n",
       " 'emp_length.6 years': 0L,\n",
       " 'emp_length.7 years': 0L,\n",
       " 'emp_length.8 years': 0L,\n",
       " 'emp_length.9 years': 0L,\n",
       " 'emp_length.< 1 year': 0L,\n",
       " 'emp_length.n/a': 0L,\n",
       " 'grade.A': 0L,\n",
       " 'grade.B': 0L,\n",
       " 'grade.C': 0L,\n",
       " 'grade.D': 1L,\n",
       " 'grade.E': 0L,\n",
       " 'grade.F': 0L,\n",
       " 'grade.G': 0L,\n",
       " 'home_ownership.MORTGAGE': 0L,\n",
       " 'home_ownership.OTHER': 0L,\n",
       " 'home_ownership.OWN': 0L,\n",
       " 'home_ownership.RENT': 1L,\n",
       " 'safe_loans': -1L,\n",
       " 'term. 36 months': 0L,\n",
       " 'term. 60 months': 1L}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: -1 \n"
     ]
    }
   ],
   "source": [
    "print 'Predicted class: %s ' % classify(my_decision_tree_new, validation_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on term. 36 months = 0\n",
      "Split on grade.A = 0\n",
      "At leaf, predicting -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(my_decision_tree_new, validation_set[0], annotate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on term. 36 months = 0\n",
      "Split on grade.A = 0\n",
      "Split on grade.B = 0\n",
      "Split on grade.C = 0\n",
      "Split on grade.D = 1\n",
      "Split on grade.E = 0\n",
      "At leaf, predicting -1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(my_decision_tree_old, validation_set[0], annotate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_classification_error(tree, data):\n",
    "    # Apply the classify(tree, x) to each row in your data\n",
    "    prediction = data.apply(lambda x: classify(tree, x))\n",
    "    \n",
    "    # Once you've made the predictions, calculate the classification error and return it\n",
    "    ## YOUR CODE HERE\n",
    "    num_mistakes = 0\n",
    "    for i in range(len(data)):\n",
    "        if prediction[i] != data['safe_loans'][i]:\n",
    "           num_mistakes = num_mistakes + 1\n",
    "    error = num_mistakes/(float(len(data))) \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3837785437311504"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(my_decision_tree_new, validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3837785437311504"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(my_decision_tree_old, validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "Split on feature grade.D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Split on feature emp_length.n/a. (96, 5)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (96 data points).\n",
      "Split on feature emp_length.< 1 year. (85, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (85 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (11 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "Split on feature grade.D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "Split on feature grade.E. (22024, 1276)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (22024 data points).\n",
      "Split on feature grade.F. (21666, 358)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (21666 data points).\n",
      "Split on feature emp_length.n/a. (20734, 932)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (20734 data points).\n",
      "Split on feature grade.G. (20638, 96)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (20638 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (96 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (932 data points).\n",
      "Split on feature grade.A. (702, 230)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (702 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (230 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (358 data points).\n",
      "Split on feature emp_length.8 years. (347, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (347 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Split on feature home_ownership.OWN. (9, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (9 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1276 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Split on feature emp_length.n/a. (96, 5)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (96 data points).\n",
      "Split on feature emp_length.< 1 year. (85, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (85 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (11 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "Split on feature grade.D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "Split on feature grade.E. (22024, 1276)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (22024 data points).\n",
      "Split on feature grade.F. (21666, 358)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (21666 data points).\n",
      "Split on feature emp_length.n/a. (20734, 932)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (20734 data points).\n",
      "Split on feature grade.G. (20638, 96)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (20638 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (96 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (932 data points).\n",
      "Split on feature grade.A. (702, 230)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (702 data points).\n",
      "Split on feature home_ownership.OTHER. (701, 1)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (701 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 7 (1 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (230 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (358 data points).\n",
      "Split on feature emp_length.8 years. (347, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (347 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Split on feature home_ownership.OWN. (9, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (9 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1276 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n"
     ]
    }
   ],
   "source": [
    "model_1 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 2, \n",
    "                                min_node_size = 100, min_error_reduction=0.0)\n",
    "model_2 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                                min_node_size = 100, min_error_reduction=0.0)\n",
    "model_3 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 14, \n",
    "                                min_node_size = 100, min_error_reduction=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data, classification error (model 1): 0.400037610144\n",
      "Training data, classification error (model 2): 0.381957876639\n",
      "Training data, classification error (model 3): 0.38193101225\n"
     ]
    }
   ],
   "source": [
    "print \"Training data, classification error (model 1):\", evaluate_classification_error(model_1, train_data)\n",
    "print \"Training data, classification error (model 2):\", evaluate_classification_error(model_2, train_data)\n",
    "print \"Training data, classification error (model 3):\", evaluate_classification_error(model_3, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data, classification error (model 1): 0.398104265403\n",
      "Validation Data, classification error (model 2): 0.383778543731\n",
      "Validation Data, classification error (model 3): 0.383778543731\n"
     ]
    }
   ],
   "source": [
    "print \"Validation Data, classification error (model 1):\", evaluate_classification_error(model_1, validation_set)\n",
    "print \"Validation Data, classification error (model 2):\", evaluate_classification_error(model_2, validation_set)\n",
    "print \"Validation Data, classification error (model 3):\", evaluate_classification_error(model_3, validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_leaves(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return count_leaves(tree['left']) + count_leaves(tree['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_nodes_1 = count_leaves(model_1)\n",
    "num_nodes_2 = count_leaves(model_2)\n",
    "num_nodes_3 = count_leaves(model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "Split on feature grade.B. (8074, 1048)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (8074 data points).\n",
      "Split on feature grade.C. (5884, 2190)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (5884 data points).\n",
      "Split on feature grade.D. (3826, 2058)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (3826 data points).\n",
      "Split on feature grade.E. (1693, 2133)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1693 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2133 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2058 data points).\n",
      "Split on feature grade.E. (2058, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2058 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (2190 data points).\n",
      "Split on feature grade.D. (2190, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2190 data points).\n",
      "Split on feature grade.E. (2190, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2190 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1048 data points).\n",
      "Split on feature emp_length.5 years. (969, 79)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (969 data points).\n",
      "Split on feature grade.C. (969, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (969 data points).\n",
      "Split on feature grade.D. (969, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (969 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (79 data points).\n",
      "Split on feature home_ownership.MORTGAGE. (34, 45)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (34 data points).\n",
      "Split on feature grade.C. (34, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (34 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (45 data points).\n",
      "Split on feature grade.C. (45, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (45 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Split on feature emp_length.n/a. (96, 5)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (96 data points).\n",
      "Split on feature emp_length.< 1 year. (85, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (85 data points).\n",
      "Split on feature grade.B. (85, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (85 data points).\n",
      "Split on feature grade.C. (85, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (85 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (11 data points).\n",
      "Split on feature grade.B. (11, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Split on feature grade.C. (11, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (11 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5 data points).\n",
      "Split on feature grade.B. (5, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (5 data points).\n",
      "Split on feature grade.C. (5, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (5 data points).\n",
      "Split on feature grade.D. (5, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (5 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "Split on feature grade.D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "Split on feature grade.E. (22024, 1276)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (22024 data points).\n",
      "Split on feature grade.F. (21666, 358)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (21666 data points).\n",
      "Split on feature emp_length.n/a. (20734, 932)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (20734 data points).\n",
      "Split on feature grade.G. (20638, 96)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (20638 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (96 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (932 data points).\n",
      "Split on feature grade.A. (702, 230)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (702 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (230 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (358 data points).\n",
      "Split on feature emp_length.8 years. (347, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (347 data points).\n",
      "Split on feature grade.A. (347, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (347 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Split on feature home_ownership.OWN. (9, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (9 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1276 data points).\n",
      "Split on feature grade.A. (1276, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1276 data points).\n",
      "Split on feature grade.B. (1276, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1276 data points).\n",
      "Split on feature grade.C. (1276, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1276 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "Split on feature grade.A. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (4701 data points).\n",
      "Split on feature grade.B. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4701 data points).\n",
      "Split on feature grade.C. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (4701 data points).\n",
      "Split on feature grade.E. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (4701 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Split on feature emp_length.n/a. (96, 5)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (96 data points).\n",
      "Split on feature emp_length.< 1 year. (85, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (85 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (11 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "Split on feature grade.D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "Split on feature grade.E. (22024, 1276)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (22024 data points).\n",
      "Split on feature grade.F. (21666, 358)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (21666 data points).\n",
      "Split on feature emp_length.n/a. (20734, 932)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (20734 data points).\n",
      "Split on feature grade.G. (20638, 96)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (20638 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (96 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (932 data points).\n",
      "Split on feature grade.A. (702, 230)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (702 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (230 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (358 data points).\n",
      "Split on feature emp_length.8 years. (347, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (347 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Split on feature home_ownership.OWN. (9, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (9 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1276 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Early stopping condition 3 reached. Minimum error reduction.\n"
     ]
    }
   ],
   "source": [
    "model_4 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                                min_node_size = 0, min_error_reduction=-1)\n",
    "model_5 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                                min_node_size = 0, min_error_reduction=0.0)\n",
    "model_6 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                                min_node_size = 0, min_error_reduction=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data, classification error (model 4): 0.383778543731\n",
      "Validation data, classification error (model 5): 0.383778543731\n",
      "Validation data, classification error (model 6): 0.503446790177\n"
     ]
    }
   ],
   "source": [
    "print \"Validation data, classification error (model 4):\", evaluate_classification_error(model_4, validation_set)\n",
    "print \"Validation data, classification error (model 5):\", evaluate_classification_error(model_5, validation_set)\n",
    "print \"Validation data, classification error (model 6):\", evaluate_classification_error(model_6, validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "Split on feature grade.B. (8074, 1048)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (8074 data points).\n",
      "Split on feature grade.C. (5884, 2190)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (5884 data points).\n",
      "Split on feature grade.D. (3826, 2058)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (3826 data points).\n",
      "Split on feature grade.E. (1693, 2133)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1693 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2133 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2058 data points).\n",
      "Split on feature grade.E. (2058, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2058 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (2190 data points).\n",
      "Split on feature grade.D. (2190, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2190 data points).\n",
      "Split on feature grade.E. (2190, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2190 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1048 data points).\n",
      "Split on feature emp_length.5 years. (969, 79)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (969 data points).\n",
      "Split on feature grade.C. (969, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (969 data points).\n",
      "Split on feature grade.D. (969, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (969 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (79 data points).\n",
      "Split on feature home_ownership.MORTGAGE. (34, 45)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (34 data points).\n",
      "Split on feature grade.C. (34, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (34 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (45 data points).\n",
      "Split on feature grade.C. (45, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (45 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Split on feature emp_length.n/a. (96, 5)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (96 data points).\n",
      "Split on feature emp_length.< 1 year. (85, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (85 data points).\n",
      "Split on feature grade.B. (85, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (85 data points).\n",
      "Split on feature grade.C. (85, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (85 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (11 data points).\n",
      "Split on feature grade.B. (11, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Split on feature grade.C. (11, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (11 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5 data points).\n",
      "Split on feature grade.B. (5, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (5 data points).\n",
      "Split on feature grade.C. (5, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (5 data points).\n",
      "Split on feature grade.D. (5, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (5 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "Split on feature grade.D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "Split on feature grade.E. (22024, 1276)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (22024 data points).\n",
      "Split on feature grade.F. (21666, 358)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (21666 data points).\n",
      "Split on feature emp_length.n/a. (20734, 932)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (20734 data points).\n",
      "Split on feature grade.G. (20638, 96)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (20638 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (96 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (932 data points).\n",
      "Split on feature grade.A. (702, 230)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (702 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (230 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (358 data points).\n",
      "Split on feature emp_length.8 years. (347, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (347 data points).\n",
      "Split on feature grade.A. (347, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (347 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Split on feature home_ownership.OWN. (9, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (9 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1276 data points).\n",
      "Split on feature grade.A. (1276, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1276 data points).\n",
      "Split on feature grade.B. (1276, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1276 data points).\n",
      "Split on feature grade.C. (1276, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1276 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "Split on feature grade.A. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (4701 data points).\n",
      "Split on feature grade.B. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4701 data points).\n",
      "Split on feature grade.C. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (4701 data points).\n",
      "Split on feature grade.E. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (4701 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "Split on feature grade.B. (8074, 1048)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (8074 data points).\n",
      "Split on feature grade.C. (5884, 2190)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (5884 data points).\n",
      "Split on feature grade.D. (3826, 2058)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (3826 data points).\n",
      "Split on feature grade.E. (1693, 2133)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1693 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2133 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2058 data points).\n",
      "Split on feature grade.E. (2058, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2058 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (2190 data points).\n",
      "Split on feature grade.D. (2190, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2190 data points).\n",
      "Split on feature grade.E. (2190, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2190 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1048 data points).\n",
      "Split on feature emp_length.5 years. (969, 79)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (969 data points).\n",
      "Split on feature grade.C. (969, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (969 data points).\n",
      "Split on feature grade.D. (969, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (969 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (79 data points).\n",
      "Split on feature home_ownership.MORTGAGE. (34, 45)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (34 data points).\n",
      "Split on feature grade.C. (34, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (34 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (45 data points).\n",
      "Split on feature grade.C. (45, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (45 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Split on feature emp_length.n/a. (96, 5)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (96 data points).\n",
      "Split on feature emp_length.< 1 year. (85, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (85 data points).\n",
      "Split on feature grade.B. (85, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (85 data points).\n",
      "Split on feature grade.C. (85, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (85 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (11 data points).\n",
      "Split on feature grade.B. (11, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Split on feature grade.C. (11, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (11 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5 data points).\n",
      "Split on feature grade.B. (5, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (5 data points).\n",
      "Split on feature grade.C. (5, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (5 data points).\n",
      "Split on feature grade.D. (5, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (5 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "Split on feature grade.D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "Split on feature grade.E. (22024, 1276)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (22024 data points).\n",
      "Split on feature grade.F. (21666, 358)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (21666 data points).\n",
      "Split on feature emp_length.n/a. (20734, 932)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (20734 data points).\n",
      "Split on feature grade.G. (20638, 96)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (20638 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (96 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (932 data points).\n",
      "Split on feature grade.A. (702, 230)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (702 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (230 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (358 data points).\n",
      "Split on feature emp_length.8 years. (347, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (347 data points).\n",
      "Split on feature grade.A. (347, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (347 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Split on feature home_ownership.OWN. (9, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (9 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1276 data points).\n",
      "Split on feature grade.A. (1276, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1276 data points).\n",
      "Split on feature grade.B. (1276, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1276 data points).\n",
      "Split on feature grade.C. (1276, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1276 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "Split on feature grade.A. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (4701 data points).\n",
      "Split on feature grade.B. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4701 data points).\n",
      "Split on feature grade.C. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (4701 data points).\n",
      "Split on feature grade.E. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (4701 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 0 (37224 data points).\n",
      "Split on feature term. 36 months. (9223, 28001)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (9223 data points).\n",
      "Split on feature grade.A. (9122, 101)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9122 data points).\n",
      "Split on feature grade.B. (8074, 1048)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (8074 data points).\n",
      "Split on feature grade.C. (5884, 2190)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (5884 data points).\n",
      "Split on feature grade.D. (3826, 2058)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (3826 data points).\n",
      "Split on feature grade.E. (1693, 2133)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1693 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2133 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2058 data points).\n",
      "Split on feature grade.E. (2058, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2058 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (2190 data points).\n",
      "Split on feature grade.D. (2190, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (2190 data points).\n",
      "Split on feature grade.E. (2190, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2190 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1048 data points).\n",
      "Split on feature emp_length.5 years. (969, 79)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (969 data points).\n",
      "Split on feature grade.C. (969, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (969 data points).\n",
      "Split on feature grade.D. (969, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (969 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (79 data points).\n",
      "Split on feature home_ownership.MORTGAGE. (34, 45)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (34 data points).\n",
      "Split on feature grade.C. (34, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (34 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (45 data points).\n",
      "Split on feature grade.C. (45, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (45 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (101 data points).\n",
      "Split on feature emp_length.n/a. (96, 5)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (96 data points).\n",
      "Split on feature emp_length.< 1 year. (85, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (85 data points).\n",
      "Split on feature grade.B. (85, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (85 data points).\n",
      "Split on feature grade.C. (85, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (85 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (11 data points).\n",
      "Split on feature grade.B. (11, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Split on feature grade.C. (11, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (11 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (5 data points).\n",
      "Split on feature grade.B. (5, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (5 data points).\n",
      "Split on feature grade.C. (5, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (5 data points).\n",
      "Split on feature grade.D. (5, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (5 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (28001 data points).\n",
      "Split on feature grade.D. (23300, 4701)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (23300 data points).\n",
      "Split on feature grade.E. (22024, 1276)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (22024 data points).\n",
      "Split on feature grade.F. (21666, 358)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (21666 data points).\n",
      "Split on feature emp_length.n/a. (20734, 932)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (20734 data points).\n",
      "Split on feature grade.G. (20638, 96)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (20638 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (96 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (932 data points).\n",
      "Split on feature grade.A. (702, 230)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (702 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (230 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (358 data points).\n",
      "Split on feature emp_length.8 years. (347, 11)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (347 data points).\n",
      "Split on feature grade.A. (347, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (347 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (11 data points).\n",
      "Split on feature home_ownership.OWN. (9, 2)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (9 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (2 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (1276 data points).\n",
      "Split on feature grade.A. (1276, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (1276 data points).\n",
      "Split on feature grade.B. (1276, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (1276 data points).\n",
      "Split on feature grade.C. (1276, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (1276 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4701 data points).\n",
      "Split on feature grade.A. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (4701 data points).\n",
      "Split on feature grade.B. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (4701 data points).\n",
      "Split on feature grade.C. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (4701 data points).\n",
      "Split on feature grade.E. (4701, 0)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (4701 data points).\n",
      "Early stopping condition 1 reached. Reached maximum depth.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 6 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 5 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 4 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (0 data points).\n",
      "Stopping condition 1 reached. All data points have the same target value.\n"
     ]
    }
   ],
   "source": [
    "model_7 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                                min_node_size = 0, min_error_reduction=-1) \n",
    "model_8 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                                min_node_size = 2000, min_error_reduction=-1)\n",
    "model_9 = decision_tree_create(train_data, features, 'safe_loans', max_depth = 6, \n",
    "                                min_node_size = 50000, min_error_reduction=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data, classification error (model 7): 0.383778543731\n",
      "Validation data, classification error (model 8): 0.383778543731\n",
      "Validation data, classification error (model 9): 0.383778543731\n"
     ]
    }
   ],
   "source": [
    "print \"Validation data, classification error (model 7):\", evaluate_classification_error(model_7, validation_set)\n",
    "print \"Validation data, classification error (model 8):\", evaluate_classification_error(model_8, validation_set)\n",
    "print \"Validation data, classification error (model 9):\", evaluate_classification_error(model_9, validation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
